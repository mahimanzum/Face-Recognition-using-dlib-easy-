{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_easy.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m51qTSSJGcpj","colab_type":"code","colab":{}},"source":["import dlib\n","import scipy.misc\n","import numpy as np\n","#Block 2 sync colabserver with drive\n","\n","# Get Face Detector from dlib\n","# This allows us to detect faces in images\n","face_detector = dlib.get_frontal_face_detector()\n","# Get Pose Predictor from dlib\n","!ls \"drive/\"\n","# This allows us to detect landmark points in faces and understand the pose/angle of the face\n","shape_predictor = dlib.shape_predictor(\"drive/Face Recognition/Vai's FR/shape_predictor_68_face_landmarks.dat\")\n","# Get the face recognition model\n","# This is what gives us the face encodings (numbers that identify the face of a particular person)\n","face_recognition_model = dlib.face_recognition_model_v1('dlib_face_recognition_resnet_model_v1.dat')\n","# This is the tolerance for face comparisons\n","# The lower the number - the stricter the comparison\n","# To avoid false matches, use lower value\n","# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n","# 0.5-0.6 works well\n","TOLERANCE = 0.6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GZO6siEWUsOa","colab_type":"code","colab":{}},"source":["#Block 1 server setup \n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLcwoGuZUx3U","colab_type":"code","colab":{}},"source":["#Block 2 sync colabserver with drive\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1I--1O08HBGL","colab_type":"code","outputId":"33718216-f2b3-454f-e1f7-d626c492c397","executionInfo":{"status":"ok","timestamp":1560924295572,"user_tz":-360,"elapsed":2733,"user":{"displayName":"Mahim Anzum Haque pantho","photoUrl":"https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg","userId":"07659887497514272211"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["!ls 'drive/Face Recognition/From_git/'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A1.jpg\t\t\t Face_recog.ipynb\t\t      model\n","A.jpg\t\t\t gen_emb.py\t\t\t      README.md\n","Ba.jpg\t\t\t gen_emb.pyc\t\t\t      Untitled.ipynb\n","CoreML-Convertion.ipynb  haarcascade_frontalface_default.xml  utils.lua\n","evaluation\t\t Keras-Openface-Accuracy.ipynb\t      utils.py\n","exportWeight.lua\t Keras-openface-convertion.ipynb      utils.pyc\n","facenet.py\t\t lfw.py\t\t\t\t      weights\n","facenet.pyc\t\t lfw.pyc\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BMqgu3R9R7Ps","colab_type":"code","colab":{}},"source":["import dlib\n","import scipy.misc\n","import imageio \n","import numpy as np\n","#Block 2 sync colabserver with drive\n","# Get Face Detector from dlib\n","# This allows us to detect faces in images\n","face_detector = dlib.get_frontal_face_detector()\n","# Get Pose Predictor from dlib\n","# This allows us to detect landmark points in faces and understand the pose/angle of the face\n","shape_predictor = dlib.shape_predictor(\"drive/Face Recognition/Vai's FR/shape_predictor_68_face_landmarks.dat\")\n","# Get the face recognition model\n","# This is what gives us the face encodings (numbers that identify the face of a particular person)\n","face_recognition_model = dlib.face_recognition_model_v1(\"drive/Face Recognition/Vai's FR/dlib_face_recognition_resnet_model_v1.dat\")\n","# This is the tolerance for face comparisons\n","# The lower the number - the stricter the comparison\n","# To avoid false matches, use lower value\n","# To avoid false negatives (i.e. faces of the same person doesn't match), use higher value\n","# 0.5-0.6 works well\n","TOLERANCE = 0.6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"56Ini-elTqzg","colab_type":"code","colab":{}},"source":["# This function will take an image and return its face encodings using the neural network\n","def get_face_encodings(path_to_image):\n","    # Load image using scipy\n","    image = imageio.imread(path_to_image)\n","    # Detect faces using the face detector\n","    detected_faces = face_detector(image, 1)\n","    # Get pose/landmarks of those faces\n","    # Will be used as an input to the function that computes face encodings\n","    # This allows the neural network to be able to produce similar numbers for faces of the same people, regardless of camera angle and/or face positioning in the image\n","    shapes_faces = [shape_predictor(image, face) for face in detected_faces]\n","    # For every face detected, compute the face encodings\n","    return [np.array(face_recognition_model.compute_face_descriptor(image, face_pose, 1)) for face_pose in shapes_faces]\n","# This function takes a list of known faces\n","def compare_face_encodings(known_faces, face):\n","    # Finds the difference between each known face and the given face (that we are comparing)\n","    # Calculate norm for the differences with each known face\n","    # Return an array with True/Face values based on whether or not a known face matched with the given face\n","    # A match occurs when the (norm) difference between a known face and the given face is less than or equal to the TOLERANCE value\n","    return (np.linalg.norm(known_faces - face, axis=1) <= TOLERANCE)\n","# This function returns the name of the person whose image matches with the given face (or 'Not Found')\n","# known_faces is a list of face encodings\n","# names is a list of the names of people (in the same order as the face encodings - to match the name with an encoding)\n","# face is the face we are looking for\n","def find_match(known_faces, names, face):\n","    # Call compare_face_encodings to get a list of True/False values indicating whether or not there's a match\n","    matches = compare_face_encodings(known_faces, face)\n","    # Return the name of the first match\n","    count = 0\n","    for match in matches:\n","        if match:\n","            return names[count]\n","        count += 1\n","    # Return not found if no match found\n","    return 'Not Found'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gtB4PaHXesq","colab_type":"code","colab":{}},"source":["# Get path to all the known images\n","# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n","import os\n","image_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir(\"drive/Face Recognition/Vai's FR/images/\"))\n","# Sort in alphabetical order\n","image_filenames = sorted(image_filenames)\n","# Get full paths to images\n","paths_to_images = [\"drive/Face Recognition/Vai's FR/images/\" + x for x in image_filenames]\n","# List of face encodings we have\n","face_encodings = []\n","# Loop over images to get the encoding one by one\n","for path_to_image in paths_to_images:\n","    # Get face encodings from the image\n","    face_encodings_in_image = get_face_encodings(path_to_image)\n","    # Make sure there's exactly one face in the image\n","    if len(face_encodings_in_image) != 1:\n","        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n","        exit()\n","    # Append the face encoding found in that image to the list of face encodings we have\n","    face_encodings.append(get_face_encodings(path_to_image)[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Fo7qzKNYE8-","colab_type":"code","outputId":"8ca2dfb0-3908-47c2-89a1-8f1ad152548b","executionInfo":{"status":"ok","timestamp":1560927324992,"user_tz":-360,"elapsed":4015,"user":{"displayName":"Mahim Anzum Haque pantho","photoUrl":"https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg","userId":"07659887497514272211"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Get path to all the test images\n","# Filtering on .jpg extension - so this will only work with JPEG images ending with .jpg\n","test_filenames = filter(lambda x: x.endswith('.jpg'), os.listdir(\"drive/Face Recognition/Vai's FR/test/\"))\n","# Get full paths to test images\n","paths_to_test_images = [\"drive/Face Recognition/Vai's FR/test/\" + x for x in test_filenames]\n","# Get list of names of people by eliminating the .JPG extension from image filenames\n","names = [x[:-4] for x in image_filenames]\n","# Iterate over test images to find match one by one\n","for path_to_image in paths_to_test_images:\n","    # Get face encodings from the test image\n","    face_encodings_in_image = get_face_encodings(path_to_image)\n","    # Make sure there's exactly one face in the image\n","    #print(path_to_image)\n","    if len(face_encodings_in_image) != 1:\n","        print(\"Please change image: \" + path_to_image + \" - it has \" + str(len(face_encodings_in_image)) + \" faces; it can only have one\")\n","        exit()\n","    # Find match for the face encoding found in this test image\n","    match = find_match(face_encodings, names, face_encodings_in_image[0])\n","    # Print the path of test image and the corresponding match\n","    print(path_to_image, match)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["drive/Face Recognition/Vai's FR/test/o.jpg obama\n","drive/Face Recognition/Vai's FR/test/A1.jpg pantho\n","drive/Face Recognition/Vai's FR/test/elon.jpg Not Found\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FhYfetqoYcTu","colab_type":"code","outputId":"b2013a11-b5da-46dc-81d2-83153aefca02","executionInfo":{"status":"ok","timestamp":1560927222791,"user_tz":-360,"elapsed":3309,"user":{"displayName":"Mahim Anzum Haque pantho","photoUrl":"https://lh4.googleusercontent.com/-t-OANPV3UrY/AAAAAAAAAAI/AAAAAAAAJW8/eEwnrZoH7dM/s64/photo.jpg","userId":"07659887497514272211"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!ls \"drive/Face Recognition/Vai's FR/test/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["A1.jpg\telon.jpg  ob.jpg\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e3G_354KY4o9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvToiV5HZSyu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}